{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 检测和分析人脸\r\n",
        "\r\n",
        "计算机视觉解决方案通常需要一个人工智能 (AI) 解决方案才能检测、分析或识别人脸。例如，假设零售公司 Northwind Traders 决定实现一个“智能商店”，并使用 AI 服务监控商店，以识别需要帮助的顾客，并引导员工为其提供帮助。达成该目标的一种方法是执行面部检测和分析，也就是确定图像中是否有人脸，并在存在人脸时分析其特征。\r\n",
        "\r\n",
        "![正在分析人脸的机器人](./images/face_analysis.jpg)\r\n",
        "\r\n",
        "## 使用人脸认知服务来检测人脸\r\n",
        "\r\n",
        "假设 Northwind Traders 想要创建的智能商店系统需要能够检测到顾客并分析其面部特征。在 Microsoft Azure 中，可以使用 Azure 认知服务中包含的“**人脸**”功能来做到这一点。\r\n",
        "\r\n",
        "### 创建认知服务资源\r\n",
        "\r\n",
        "首先，在 Azure 订阅中创建**认知服务**资源。\r\n",
        "\r\n",
        "> **备注**：如果已有认知服务资源，则只需在 Azure 门户中打开其“**快速入门**”页面，然后将其密钥和终结点复制到下面的单元格中即可。否则，请按照以下步骤创建认知服务资源。\r\n",
        "\r\n",
        "1. 在另一个浏览器标签页中，打开 Azure 门户 (https://portal.azure.com) 并使用 Microsoft 帐户登录。\r\n",
        "2. 单击“**&#65291;创建资源**”按钮，搜索“*认知服务*”并以如下设置创建**认知服务**资源：\r\n",
        "    * **订阅**： *你的 Azure 订阅*。\r\n",
        "    * **资源组**： *选择或创建具有唯一名称的资源组*。\r\n",
        "    * **区域**： *选择任何可用区域*：\r\n",
        "    * **名称**： *输入一个唯一名称*。\r\n",
        "    * **定价层**：S0\r\n",
        "    * **我确认我已阅读并理解上述通知**：已选中。\r\n",
        "3. 等待部署完成。然后转到认知服务资源，并单击“**概述**”页面上的链接以管理该服务的密钥。你将需要使用终结点和密钥从客户端应用程序连接到认知服务资源。\r\n",
        "\r\n",
        "### 获取认知服务资源的密钥和终结点\r\n",
        "\r\n",
        "要使用认知服务资源，客户端应用程序需要其终结点和身份验证密钥：\r\n",
        "\r\n",
        "1. 进入 Azure 门户，在认知服务资源的“**密钥和终结点**”页面上复制资源的“**Key1**”，并将其粘贴到以下代码中，替换“**YOUR_COG_KEY**”。\r\n",
        "\r\n",
        "2. 复制资源的**终结点**，并将其粘贴到以下代码中，替换“**YOUR_COG_ENDPOINT**”。\r\n",
        "\r\n",
        "3. 通过单击位于单元格左上角的“运行单元格”<span>&#9655;</span> 按钮运行下方单元格中的代码。"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "cog_key = 'YOUR_COG_KEY'\n",
        "cog_endpoint = 'YOUR_COG_ENDPOINT'\n",
        "\n",
        "print('Ready to use cognitive services at {} using key {}'.format(cog_endpoint, cog_key))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1599693964655
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "现在你已准备好认知服务资源，可以使用人脸服务来检测商店中的人脸。\r\n",
        "\r\n",
        "运行下面的代码单元格以查看示例。"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.cognitiveservices.vision.face import FaceClient\n",
        "from msrest.authentication import CognitiveServicesCredentials\n",
        "from python_code import faces\n",
        "import os\n",
        "%matplotlib inline\n",
        "\n",
        "# 创建人脸检测客户端。\r\n",
        "face_client = FaceClient(cog_endpoint, CognitiveServicesCredentials(cog_key))\n",
        "\n",
        "# 打开图像\r\n",
        "image_path = os.path.join('data', 'face', 'store_cam2.jpg')\n",
        "image_stream = open(image_path, \"rb\")\n",
        "\n",
        "# 检测人脸\r\n",
        "detected_faces = face_client.face.detect_with_stream(image=image_stream)\n",
        "\n",
        "# 显示人脸（python_code/faces.py 中的代码）\r\n",
        "faces.show_faces(image_path, detected_faces)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1599693970079
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "系统会为检测到的每张人脸分配一个唯一的 ID，以便应用程序识别检测到的每张人脸。\r\n",
        "\r\n",
        "运行下面的单元格以查看更多购物者人脸对应的 ID。"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# 打开图像\r\n",
        "image_path = os.path.join('data', 'face', 'store_cam3.jpg')\n",
        "image_stream = open(image_path, \"rb\")\n",
        "\n",
        "# 检测人脸\r\n",
        "detected_faces = face_client.face.detect_with_stream(image=image_stream)\n",
        "\n",
        "# 显示人脸（python_code/faces.py 中的代码）\r\n",
        "faces.show_faces(image_path, detected_faces, show_id=True)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1599693970447
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 分析面部特征\r\n",
        "\r\n",
        "人脸服务提供的功能远不止检测人脸。它还可通过分析面部特征和表情来判断年龄和情绪状态。例如，请运行下面的代码来分析购物者的面部特征。"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# 打开图像\r\n",
        "image_path = os.path.join('data', 'face', 'store_cam1.jpg')\n",
        "image_stream = open(image_path, \"rb\")\n",
        "\n",
        "# 检测人脸和指定的面部特征\r\n",
        "attributes = ['age', 'emotion']\n",
        "detected_faces = face_client.face.detect_with_stream(image=image_stream, return_face_attributes=attributes)\n",
        "\n",
        "# 显示人脸和特征（python_code/faces.py 中的代码）\r\n",
        "faces.show_face_attributes(image_path, detected_faces)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1599693971321
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "根据图像中检测到的顾客的情绪评分，这位顾客似乎对购物体验非常满意。\r\n",
        "\r\n",
        "## 查找相似人脸 \r\n",
        "\r\n",
        "为检测到的每张人脸创建的人脸 ID 用于单独识别其人脸检测信息。通过使用这些 ID，可以将检测到的人脸与之前检测到的人脸进行比较，并找到具有相似特征的人脸。\r\n",
        "\r\n",
        "例如，请运行下面的单元格，将一张图像中的某位购物者与另一张图像中的购物者们进行比较，并找到与之匹配的人脸。"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# 获取图像 1 中第一张人脸的 ID\r\n",
        "image_1_path = os.path.join('data', 'face', 'store_cam3.jpg')\n",
        "image_1_stream = open(image_1_path, \"rb\")\n",
        "image_1_faces = face_client.face.detect_with_stream(image=image_1_stream)\n",
        "face_1 = image_1_faces[0]\n",
        "\n",
        "# 获取第二张图像中的人脸 ID\r\n",
        "image_2_path = os.path.join('data', 'face', 'store_cam2.jpg')\n",
        "image_2_stream = open(image_2_path, \"rb\")\n",
        "image_2_faces = face_client.face.detect_with_stream(image=image_2_stream)\n",
        "image_2_face_ids = list(map(lambda face: face.face_id, image_2_faces))\n",
        "\n",
        "# 在图像 2 中查找与图像 1 中的人脸相似的人脸\r\n",
        "similar_faces = face_client.face.find_similar(face_id=face_1.face_id, face_ids=image_2_face_ids)\n",
        "\n",
        "# 显示图像 1 中的人脸以及图像 2 中与其相似的人脸（python_code/face.py 中的代码）\r\n",
        "faces.show_similar_faces(image_1_path, face_1, image_2_path, image_2_faces, similar_faces)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1599693972555
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 识别人脸\r\n",
        "\r\n",
        "目前你已了解人脸服务可以检测人脸和面部特征，并且可以识别出两张相似的脸。你可以再前进一步，实现一个*面部识别*解决方案，在其中训练人脸服务来识别特定人员的脸。此类解决方案的应用范围非常广泛，比如在社交媒体应用程序中自动标记朋友的照片，或者将面部识别作为生物特征身份验证系统的一部分。\r\n",
        "\r\n",
        "要了解其中的原理，让我们假设 Northwind Traders 公司希望使用面部识别来确保只有 IT 部门中得到授权的员工才能访问安全系统。\r\n",
        "\r\n",
        "首先，我们要创建一个*人员组*来代表这些得到授权的员工。"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "group_id = 'employee_group_id'\n",
        "try:\n",
        "    # 删除已存在的组\n",
        "    face_client.person_group.delete(group_id)\n",
        "except Exception as ex:\n",
        "    print(ex.message)\n",
        "finally:\n",
        "    face_client.person_group.create(group_id, 'employees')\n",
        "    print ('Group created!')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1599693973492
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "创建好该*人员组*后，就能为其中应该包括的每位员工添加一个对应的“*人员*”，然后为每个人员录入多张照片，从而让人脸服务学习每个人独特的面部特征。提供的图像最好是能展示同一个人不同的姿势和不同的面部表情。\r\n",
        "\r\n",
        "我们会添加一个名叫 Wendell 的员工，并录入该员工的三张照片。"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import os\n",
        "%matplotlib inline\n",
        "\n",
        "# 将一个人员 (Wendell) 添加到组\r\n",
        "wendell = face_client.person_group_person.create(group_id, 'Wendell')\n",
        "\n",
        "# 获取 Wendell 的照片\r\n",
        "folder = os.path.join('data', 'face', 'wendell')\n",
        "wendell_pics = os.listdir(folder)\n",
        "\n",
        "# 录入照片\r\n",
        "i = 0\n",
        "fig = plt.figure(figsize=(8, 8))\n",
        "for pic in wendell_pics:\n",
        "    # 将每张照片添加到个人组\n",
        "    img_path = os.path.join(folder, pic)\n",
        "    img_stream = open(img_path, \"rb\")\n",
        "    face_client.person_group_person.add_face_from_stream(group_id, wendell.person_id, img_stream)\n",
        "\n",
        "    # 显示每个图像\n",
        "    img = Image.open(img_path)\n",
        "    i +=1\n",
        "    a=fig.add_subplot(1,len(wendell_pics), i)\n",
        "    a.axis('off')\n",
        "    imgplot = plt.imshow(img)\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1599693976898
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "添加人员并录入照片后，即可训练人脸服务来识别各个人员。"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "face_client.person_group.train(group_id)\n",
        "print('Trained!')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1599693977046
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "现在，你可以使用训练好的模型在图像中识别已录入的人脸。"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# 获取第二张图像中的人脸 ID\r\n",
        "image_path = os.path.join('data', 'face', 'employees.jpg')\n",
        "image_stream = open(image_path, \"rb\")\n",
        "image_faces = face_client.face.detect_with_stream(image=image_stream)\n",
        "image_face_ids = list(map(lambda face: face.face_id, image_faces))\n",
        "\n",
        "# 获取已录入的人脸对应的姓名\r\n",
        "face_names = {}\n",
        "recognized_faces = face_client.face.identify(image_face_ids, group_id)\n",
        "for face in recognized_faces:\n",
        "    person_name = face_client.person_group_person.get(group_id, face.candidates[0].person_id).name\n",
        "    face_names[face.face_id] = person_name\n",
        "\n",
        "# 显示识别到的人脸\r\n",
        "faces.show_recognized_faces(image_path, image_faces, face_names)\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1599693994820
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 了解详细信息\r\n",
        "\r\n",
        "要详细了解人脸认知服务，请参阅[人脸文档](https://docs.microsoft.com/azure/cognitive-services/face/)\r\n"
      ],
      "metadata": {}
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "kernel_info": {
      "name": "python3-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}